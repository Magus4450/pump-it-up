{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa71a663",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Import our custom modules\n",
    "# NOTE: Make sure 'get_preset' is in 'src/preprocessing/presets.py'\n",
    "from src.preprocessing.presets import get_preset \n",
    "from src.model.models import create_and_return_all_models\n",
    "from src.hyperparameter_tuning import get_param_dists, run_hyperparameter_search\n",
    "\n",
    "# ## 2. Load and Preprocess Data\n",
    "print(\"--- Step 1: Loading and Preprocessing Data ---\")\n",
    "train_values = pd.read_csv(\"data/train_set_values.csv\")\n",
    "train_labels = pd.read_csv(\"data/train_set_labels.csv\")\n",
    "test_values  = pd.read_csv(\"data/test_set_values.csv\")\n",
    "train_df = pd.merge(train_values, train_labels, on=\"id\", how=\"left\")\n",
    "\n",
    "# Use your predefined preprocessing pipeline\n",
    "preset_name = \"log_transform+remove_correlated+feature_engineer\"\n",
    "pre = get_preset(preset_name, list(train_df.columns))\n",
    "\n",
    "train_processed = pre.fit_transform(train_df)\n",
    "test_processed  = pre.transform(test_values)\n",
    "print(\"Data preprocessing complete.\")\n",
    "\n",
    "# ## 3. Prepare Data for Modeling\n",
    "X = train_processed.drop(columns=[\"status_group\"])\n",
    "y_raw = train_processed[\"status_group\"]\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y_raw)\n",
    "\n",
    "# ## 4. Run Cross-Validated Hyperparameter Search\n",
    "# Get the dictionary of untrained model pipelines\n",
    "# We pass X to the function so it can identify the numeric columns for scaling\n",
    "models_to_tune = create_and_return_all_models(X_train=X, seed=42)\n",
    "\n",
    "# Get the dictionary of parameter distributions\n",
    "param_dists = get_param_dists()\n",
    "\n",
    "# Run the search. Set n_iter to a higher number (e.g., 25) for a more thorough search.\n",
    "summary_df, best_estimators = run_hyperparameter_search(models_to_tune, param_dists, X, y, n_iter=10)\n",
    "\n",
    "print(\"\\n--- Hyperparameter Search Summary ---\")\n",
    "print(summary_df)\n",
    "\n",
    "# ## 5. Create Submission with the Winning Model\n",
    "winner_name = summary_df.index[0]\n",
    "winner_model = best_estimators[winner_name]\n",
    "\n",
    "print(f\"\\n--- Winning Model: {winner_name} ---\")\n",
    "print(f\"Best Parameters Found: {summary_df.loc[winner_name, 'best_params']}\")\n",
    "\n",
    "# Prepare the test data for prediction\n",
    "X_test = test_processed.copy()\n",
    "\n",
    "# Make predictions\n",
    "test_pred_encoded = winner_model.predict(X_test)\n",
    "\n",
    "# Decode predictions back to original labels\n",
    "test_pred_labels = le.inverse_transform(test_pred_encoded)\n",
    "\n",
    "# Create and save submission file\n",
    "submission_df = pd.DataFrame({\n",
    "    'id': test_values['id'],\n",
    "    'status_group': test_pred_labels\n",
    "})\n",
    "submission_filename = f\"submission_{winner_name.replace(' ', '_')}.csv\"\n",
    "submission_df.to_csv(submission_filename, index=False)\n",
    "print(f\"\\nSubmission file saved as '{submission_filename}'\")\n",
    "\n",
    "print(\"\\n--- Project Finished ---\")\n",
    "print(\"Final submission head:\")\n",
    "print(submission_df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pump-it-up (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
